---
title: "Risk Scaling and Transformation"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Risk Scaling and Transformation}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, message = FALSE}
library(riskintroanalysis)
library(riskintrodata)
library(dplyr)
library(sf)
library(ggplot2)
```

## Introduction

**Risk scaling** transforms risk scores from one numerical range to another while optionally applying a mathematical transformation to change the distribution of values. This is a critical step when:

1. **Comparing multiple risk sources** - Different risk methods may use different scales (0-12 for emission-based risks, variable ranges for raster-based risks). All must be scaled to a common range (typically 0-100) before they can be compared.

2. **Emphasizing or de-emphasizing risk levels** - Non-linear transformations allow you to adjust the relative importance of high vs. low risk scores to match expert field knowledge.
Direct transformations such as quadratic of exponential emphasize high scores, while their inverse counterparts compress high score values in favour of the lower end.

This vignette explains:

- Why and when to use non-linear scaling
- The mathematical functions available and their effects
- How to choose the right transformation method
- Practical examples with real data

## Why Non-Linear Scaling?

Linear scaling simply stretches or compresses values proportionally. **Non-linear transformations** change the relative spacing between values, allowing you to:

### Emphasize High Scores (Exponential, Quadratic)

When you want to **amplify differences between high-score areas** while compressing low-score differences:

- **Use case**: Small variations in the low-end of the score scale don't make much difference, while variations in the upper end of the score scale have a larger impact on the risk.
- **Effect**: Low scores correspond all to a roughly similar low risk while high scores are more spread over the risk scale.

### Emphisize contrast (Sigmoid)

When you want to **strongly separate high and low scores**.

When you want to **moderate extreme values** while preserving middle-range distinctions:

- **Use case**: Risk is either high or low, with a quick change around an intermediate score value.
- **Effect**: Creates an S-curve that compresses both very low and very high scores towards the extremes of the risk scale.

### Expand Low Values (Inverse Transformations)

When you want to **expand differences at the low end while compressing high score values**:

- **Use case**: When small variations at the low end are important to distinguish, but differences at the high end don't matter as much.
- **Effect**: Applies the mathematical inverse function (square root for quadratic, logarithm for exponential, inverse sigmoid) to the normalized values


## Transformation Functions

The `rescale_risk_scores()` function supports four transformation methods. Here's the mathematical definition and intuitive effect of each:

### Linear

**Formula**:
$$f(x) = x$$

**Effect**: Proportional scaling with no transformation. The relative spacing between values remains unchanged.

**Normalized form** (0 to 1):
$$f_{\text{norm}}(x) = x$$

**When to use**: When the original distribution is appropriate, or when you simply need to change the numerical range without altering relationships.

```{r linear-demo, fig.width=5, fig.height=3, echo = FALSE}
x <- seq(0, 1, by = 0.01)
plot(x, x, type = "l", lwd = 2, col = "blue",
     main = "Linear Transformation",
     xlab = "Normalized input (0-1)", ylab = "Transformed output (0-1)")
grid()
```

### Quadratic

**Formula**:
$$f(x) = x^2$$

**Effect**: Emphasizes high values. Differences between high values are amplified, while differences between low values are compressed.

**Intuitive interpretation**: Risk increases very little initially, and climbs progressively quicker.

**Normalized form** (0 to 1):
$$f_{\text{norm}}(x) = x^2$$

**When to use**: The underlying risk factor entails interactions or multiplicative effects.

```{r quadratic-demo, fig.width=5, fig.height=3, echo = FALSE}
plot(x, x^2, type = "l", lwd = 2, col = "red",
     main = "Quadratic Transformation",
     xlab = "Normalized input (0-1)", ylab = "Transformed output (0-1)")
lines(x, x, lty = 2, col = "grey")
grid()
legend("topleft", legend = c("Quadratic", "Linear (reference)"),
       col = c("red", "grey"), lwd = c(2, 1), lty = c(1, 2))
```



### Exponential

**Formula**:
$$f(x) = \frac{e^{kx} - 1}{e^{k} - 1}$$

where $k = 1$ is the growth rate parameter.

**Effect**: Strongly emphasizes high values. Even more aggressive than quadratic at amplifying high-score areas.

**Intuitive interpretation**: Risk remains low up to some point where it starts to climb progressively quicker.

**Normalized form** (0 to 1):
$$f_{\text{norm}}(x) = \frac{e^{x} - 1}{e - 1}$$

**When to use**: The underlying risk factor entails interactions or multiplicative effects.

```{r exponential-demo, fig.width=5, fig.height=3, echo = FALSE}
exponential_transform <- function(x) (exp(x) - 1) / (exp(1) - 1)
plot(x, exponential_transform(x), type = "l", lwd = 2, col = "darkred",
     main = "Exponential Transformation",
     xlab = "Normalized input (0-1)", ylab = "Transformed output (0-1)")
lines(x, x^2, lty = 2, col = "red")
lines(x, x, lty = 2, col = "grey")
grid()
legend("topleft",
       legend = c("Exponential", "Quadratic", "Linear"),
       col = c("darkred", "red", "grey"), lwd = c(2, 1, 1), lty = c(1, 2, 2))
```



### Sigmoid

**Formula**:
$$f(x) = \frac{1}{1 + \left(\frac{1-x}{x}\right)^2}$$

**Effect**: Creates an S-curve that compresses both ends of the score scale towrards extreme risk values while expanding the middle range.

**Intuitive interpretation**: Risk is either high or low, with a quick progression from one extreme to the other.

**Alternative formulation** using the logistic function:
$$f(x) = \frac{1}{1 + e^{-10(x - 0.5)}}$$

**When to use**: When there are little nuances between score values, and risk becomes serious beyond some threshold.

```{r sigmoid-demo, fig.width=5, fig.height=3, echo = FALSE}
sigmoid_transform <- function(x) 1 / (1 + ((1-x)/x)^2)
# Handle edge cases
sigmoid_transform <- function(x) {
  result <- 1 / (1 + ((1-x)/x)^2)
  result[x == 0] <- 0
  result[x == 1] <- 1
  result
}
plot(x, sigmoid_transform(x), type = "l", lwd = 2, col = "purple",
     main = "Sigmoid Transformation",
     xlab = "Normalized input (0-1)", ylab = "Transformed output (0-1)")
lines(x, x, lty = 2, col = "grey")
grid()
legend("topleft", legend = c("Sigmoid", "Linear (reference)"),
       col = c("purple", "grey"), lwd = c(2, 1), lty = c(1, 2))
```




## Inverse Transformations

Each transformation can be **inverted** by setting `inverse = TRUE`. The inverse functions apply the mathematical inverse of the transformation:

| Method | Forward | Inverse |
|--------|---------|---------|
| Linear | $x$ | $x$ (same) |
| Quadratic | $x^2$ | $\sqrt{x}$ |
| Exponential | $\frac{e^x - 1}{e - 1}$ | $\frac{-\log(1 - x(1 - e^{-1}))}{1}$ |
| Sigmoid | $\frac{1}{1 + (\frac{1-x}{x})^2}$ | $\frac{1}{\sqrt{\frac{1}{x} - 1} + 1}$ |

**Effect**: Invert the compressive or expansive action on variations of the scores. When a transformation expands some range of scores, the inverse transformation compresses them, and viceversa.

For instance, if risk increases very quickly at the begining of the score range, but it progressively slows down at higher score values, you could use an inverted quadratic or exponential scaling.

**Important note**: The `inverse` parameter applies the mathematical inverse of the transformation function, but does NOT __flip__ the direction of the mapping (i.e., it does not make high scores produce low risks). 
Scores that are high on the input scale remain high on the risk scale, just with a different distribution shape.

```{r inverse-demo, fig.width=7, fig.height=4, echo = FALSE}
par(mfrow = c(1, 2))
# Forward quadratic
plot(x, x^2, type = "l", lwd = 2, col = "red",
     main = "Quadratic (Forward)",
     xlab = "Input", ylab = "Output")
lines(x, x, lty = 2, col = "grey")
grid()

# Inverse quadratic (square root)
plot(x, sqrt(x), type = "l", lwd = 2, col = "blue",
     main = "Quadratic (Inverse)",
     xlab = "Input", ylab = "Output")
lines(x, x, lty = 2, col = "grey")
grid()
```

## Practical Example: Border Risk Scaling

Let's work through a complete example using border risk analysis.

### Prepare the Data

```{r prepare-data}
# Load epidemiological units
tunisia_raw <- read_sf(system.file(
  package = "riskintrodata",
  "samples", "tunisia", "epi_units", "tunisia_adm2_raw.gpkg"
))

tunisia <- validate_dataset(
  x = tunisia_raw,
  table_name = "epi_units",
  eu_name = "NAME_2",
  geometry = "geom"
) |> extract_dataset()

# Create emission risk
algeria <- erf_row(
  iso3 = "DZA",
  country = "Algeria",
  disease = "Avian infectious laryngotracheitis",
  animal_category = "Domestic",
  species = "Birds",
  disease_notification = 0,
  targeted_surveillance = 1,
  general_surveillance = 0,
  screening = 1,
  precautions_at_the_borders = 1,
  slaughter = 1,
  selective_killing_and_disposal = 1,
  zoning = 1,
  official_vaccination = 1,
  last_outbreak_end_date = as.Date("2023-06-30"),
  commerce_illegal = 0L,
  commerce_legal = 0L
)

libya <- erf_row(
  iso3 = "LBY",
  country = "Libya",
  disease = "Avian infectious laryngotracheitis",
  animal_category = "Domestic",
  species = "Birds",
  disease_notification = TRUE,
  targeted_surveillance = 1,
  general_surveillance = 0,
  screening = 1,
  precautions_at_the_borders = 0,
  slaughter = 1,
  selective_killing_and_disposal = 1,
  zoning = 1,
  official_vaccination = 1,
  last_outbreak_end_date = as.Date("2019-06-30"),
  commerce_illegal = 0L,
  commerce_legal = 1
)

emission_risk_factors <- bind_rows(algeria, libya)
emission_risk_table <- calc_emission_risk(emission_risk_factors = emission_risk_factors)

# Calculate border risk
shared_borders <- calc_border_lengths(epi_units = tunisia)
ri_borders <- calc_border_risk(
  epi_units = tunisia,
  shared_borders = shared_borders,
  emission_risk = emission_risk_table
)
```

### Compare Transformation Methods

Now let's apply different transformation methods and compare their effects:

```{r compare-methods, fig.width=8, fig.height=10}
# Apply each transformation
ri_linear <- rescale_risk_scores(
  ri_borders,
  from = c(0, 12),
  to = c(0, 100),
  method = "linear"
)

ri_quadratic <- rescale_risk_scores(
  ri_borders,
  from = c(0, 12),
  to = c(0, 100),
  method = "quadratic"
)

ri_exponential <- rescale_risk_scores(
  ri_borders,
  from = c(0, 12),
  to = c(0, 100),
  method = "exponential"
)

ri_sigmoid <- rescale_risk_scores(
  ri_borders,
  from = c(0, 12),
  to = c(0, 100),
  method = "sigmoid"
)

# Create comparison plots
library(patchwork)
p1 <- plot_risk(ri_linear) + labs(title = "Linear")
p2 <- plot_risk(ri_quadratic) + labs(title = "Quadratic")
p3 <- plot_risk(ri_exponential) + labs(title = "Exponential")
p4 <- plot_risk(ri_sigmoid) + labs(title = "Sigmoid")

(p1 | p2) / (p3 | p4)
```

### Visual Comparison of Distributions

Let's examine how the transformations affect the distribution of risk scores:

```{r distribution-comparison, fig.width=8, fig.height=5}
# Combine data for comparison
comparison_data <- data.frame(
  Linear = ri_linear$border_risk,
  Quadratic = ri_quadratic$border_risk,
  Exponential = ri_exponential$border_risk,
  Sigmoid = ri_sigmoid$border_risk
)

# Reshape for plotting
comparison_long <- tidyr::pivot_longer(
  comparison_data,
  cols = everything(),
  names_to = "Method",
  values_to = "Risk"
)

# Create violin plot with jittered points
ggplot(comparison_long, aes(x = Method, y = Risk, fill = Method)) +
  geom_violin(alpha = 0.7, draw_quantiles = c(0.25, 0.5, 0.75)) +
  geom_jitter(width = 0.1, alpha = 0.3, size = 2) +
  scale_fill_viridis_d(option = "D", direction = -1) +
  labs(
    title = "Distribution of Risk Scores by Transformation Method",
    x = "Transformation Method",
    y = "Risk Score (0-100)"
  ) +
  theme_minimal() +
  theme(legend.position = "none")
```

### Transformation Curves with Data Points

Here's how your actual data maps onto each transformation function using `rescale_risk_scores()`:

```{r transformation-curves, fig.width=8, fig.height=6}
# Create transformation curves using rescale_risk_scores
create_transformation_plot <- function(method_name, method) {
  # Create smooth curve data
  curve_data <- data.frame(original = seq(0, 12, by = 0.1))
  curve_data <- rescale_risk_scores(
    dataset = curve_data,
    cols = "original",
    from = c(0, 12),
    to = c(0, 100),
    reverse = FALSE,
    method = method,
    names_to = "transformed",
    keep_cols = TRUE
  )

  # Transform actual border risk data
  actual_data <- data.frame(original = ri_borders$border_risk)
  actual_data <- rescale_risk_scores(
    dataset = actual_data,
    cols = "original",
    from = c(0, 12),
    to = c(0, 100),
    method = method,
    names_to = "transformed",
    keep_cols = TRUE
  )

  ggplot() +
    geom_line(data = curve_data, aes(x = original, y = transformed),
              color = "grey40", linewidth = 1) +
    geom_point(data = actual_data, aes(x = original, y = transformed, color = transformed),
               size = 3, alpha = 0.6) +
    scale_color_viridis_c(option = "D", direction = -1, limits = c(0, 100)) +
    labs(
      title = paste(method_name, "Transformation"),
      x = "Original Scale (0-12)",
      y = "Transformed Scale (0-100)",
      color = "Transformed\nValue"
    ) +
    theme_minimal() +
    coord_fixed(ratio = 12/100)
}

# Create all four plots
p1 <- create_transformation_plot("Linear", "linear")
p2 <- create_transformation_plot("Quadratic", "quadratic")
p3 <- create_transformation_plot("Exponential", "exponential")
p4 <- create_transformation_plot("Sigmoid", "sigmoid")

(p1 | p2) / (p3 | p4)
```


## Combining Scaled Risks

Once risks are scaled to 0-100, they can be combined into a comprehensive risk table:

```{r combine-risks, eval=FALSE}
# Initialize risk table with common scale
rt <- risk_table(tunisia, scale = c(0, 100))

# Add risks with chosen transformations
rt <- add_risk(rt, ri_quadratic)  # Border risk with quadratic

# Add other risk sources (scaled to 0-100)
# rt <- add_risk(rt, ri_entry_points_scaled)
# rt <- add_risk(rt, ri_animal_mobility_scaled)

# Summarize to overall risk
final_risk <- summarise_scores(rt, method = "max")

plot_risk(final_risk)
```

## Technical Notes

### Normalization and Rescaling Process

The rescaling process involves three steps:

1. **Normalization**: Transform input to 0-1 range
   $$x_{\text{norm}} = \frac{x - \text{min}_{\text{old}}}{\text{max}_{\text{old}} - \text{min}_{\text{old}}}$$

2. **Transformation**: Apply the chosen function
   $$x_{\text{trans}} = f(x_{\text{norm}})$$

3. **Rescaling**: Map to target range
   $$x_{\text{final}} = x_{\text{trans}} \times (\text{max}_{\text{new}} - \text{min}_{\text{new}}) + \text{min}_{\text{new}}$$

### Attribute Preservation

The `rescale_risk_scores()` function preserves important metadata attributes:

- `scale`: Updated to reflect the new range
- `risk_col`: Updated to point to the rescaled column
- `table_name`: Preserved from the original dataset

These attributes enable automatic detection in downstream functions like `plot_risk()` and `summarise_scores()`.

## Summary

Risk scaling is a powerful tool for:

- Standardizing risks to a common scale for combination
- Adjusting the relative importance of different score levels
- Handling diverse data sources with different characteristics
- Making expert knowledge explicit through mathematical transformations

The choice of transformation method should reflect your analytical goals and field expertise. 

## Further Reading

For more information on risk analysis methods:

- [Introduction Risk](introduction-risk.html) - Combining multiple risk sources
- [Border Risk Analysis](border-risk-analysis.html) - Border-based risk calculation
- [Entry Points Analysis](entry-points-analysis.html) - Entry point risk calculation
- [Animal Mobility Analysis](animal-mobility-analysis.html) - Animal movement risk
- [Road Access Analysis](road-access-analysis.html) - Road accessibility risk
- [Additional Risks](additional-risks.html) - Custom risk factors from raster data
